# Clara - Orchestrateur central
"""
Orchestrateur principal de Clara
G√®re la conversation, l'historique et appelle le LLM
"""

import yaml
import json
import re
from datetime import datetime
from drivers.llm_driver import LLMDriver
from utils.logger import DebugLogger
from memory.helpers import save_note, save_todo, save_process, save_protocol
from memory.memory_core import get_items, search_items, delete_item, save_preference


class Orchestrator:
    """Orchestrateur central de Clara"""
    
    def __init__(self, config_path="config/settings.yaml"):
        # Charger la configuration
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # Initialiser les composants
        self.llm_driver = LLMDriver(config_path)
        
        # Historique de conversation (en m√©moire RAM)
        self.conversation_history = []
        self.max_history = self.config.get('max_history_messages', 20)
        
        # System prompt
        self.system_prompt = self._build_system_prompt()
    
    def _build_system_prompt(self):
        """Construit le prompt syst√®me de Clara"""
        return """Tu es Clara, une assistante IA intelligente et serviable.

Caract√©ristiques :
- Tu es courtoise et professionnelle
- Tu r√©ponds de mani√®re claire et concise
- Tu adaptes ta langue √† celle de l'utilisateur
- Tu es honn√™te : si tu ne sais pas quelque chose, tu le dis

Capacit√©s m√©moire (Phase 2.5) :
Tu as maintenant acc√®s √† une m√©moire persistante pour plusieurs types d'informations.

Actions disponibles :

NOTES :
- memory_save_note : Sauvegarder une note
- memory_list_notes : Lister toutes les notes
- memory_search_notes : Chercher dans les notes

TODOS :
- memory_save_todo : Enregistrer un todo (chose √† faire)
- memory_list_todos : Lister tous les todos
- memory_search_todos : Chercher dans les todos

PROCESS :
- memory_save_process : Enregistrer un processus/proc√©dure d√©taill√©e
- memory_list_processes : Lister tous les processus

PROTOCOL :
- memory_save_protocol : Enregistrer un protocole/r√®gle g√©n√©rale
- memory_list_protocols : Lister tous les protocoles

PR√âF√âRENCES :
- memory_set_preference : Enregistrer une pr√©f√©rence (langue, canal de communication, etc.)

G√âN√âRAL :
- memory_delete_item : Supprimer un √©l√©ment par ID (tous types)

Quand l'utilisateur demande de sauvegarder/lister/chercher ces √©l√©ments,
OU quand il exprime une pr√©f√©rence ("je pr√©f√®re", "d√©sormais", "√† partir de maintenant", "toujours", "ne jamais"),
tu dois RETOURNER une structure JSON d'intention dans ta r√©ponse, d√©limit√©e par des balises :

```json
{"memory_action": "save_note", "content": "texte", "tags": ["optionnel"]}
```

ou

```json
{"memory_action": "save_todo", "content": "chose √† faire", "tags": ["optionnel"]}
```

ou

```json
{"memory_action": "list_todos"}
```

ou

```json
{"memory_action": "search_notes", "query": "mot"}
```

ou

```json
{"memory_action": "delete_item", "item_id": 123}
```

IMPORTANT : Tu dois TOUJOURS r√©pondre au format texte naturel √† l'utilisateur, 
ET inclure le bloc JSON si une action m√©moire est n√©cessaire.

Pour l'instant, tu es en phase de construction (Phase 2.5).
Tu peux converser et g√©rer des notes, todos, processus et protocoles en m√©moire.
Tu n'as pas encore acc√®s √† des outils externes (fichiers, emails, etc.)."""
    
    def handle_message(self, user_message, session_id, debug_logger):
        """
        Traite un message utilisateur
        
        Args:
            user_message: Message de l'utilisateur
            session_id: ID de la session
            debug_logger: Logger de debug
        
        Returns:
            str: R√©ponse de Clara
        """
        try:
            # PR√â-V√âRIFICATION : D√©tecter si c'est une demande de lecture m√©moire
            memory_context = self._check_memory_read_intent(user_message)
            
            # Ajouter le message utilisateur √† l'historique
            self.conversation_history.append({
                'role': 'user',
                'content': user_message
            })
            
            # Construire les messages pour le LLM
            messages = self._build_prompt()
            
            # Si on a un contexte m√©moire, l'ajouter au prompt
            if memory_context:
                messages.append({
                    'role': 'system',
                    'content': f"DONN√âES M√âMOIRE R√âELLES :\n{memory_context}"
                })
            
            # Appeler le LLM
            response = self.llm_driver.generate(messages)
            clara_response = response['text']
            
            # Chercher une intention m√©moire dans la r√©ponse (pour les actions d'√©criture)
            memory_result = self._process_memory_action(clara_response)
            
            # Si une action m√©moire a √©t√© ex√©cut√©e, ajouter le r√©sultat √† la r√©ponse
            if memory_result:
                clara_response = self._clean_response(clara_response) + f"\n\n{memory_result}"
            
            # Ajouter la r√©ponse √† l'historique
            self.conversation_history.append({
                'role': 'assistant',
                'content': clara_response
            })
            
            # Limiter la taille de l'historique
            if len(self.conversation_history) > self.max_history:
                self.conversation_history = self.conversation_history[-self.max_history:]
            
            # Logger le debug
            debug_logger.log_interaction(
                user_input=user_message,
                prompt_messages=messages,
                llm_response=clara_response,
                usage=response['usage'],
                error=None
            )
            
            return clara_response
            
        except Exception as e:
            error_msg = f"Erreur : {str(e)}"
            
            # Logger l'erreur
            debug_logger.log_interaction(
                user_input=user_message,
                prompt_messages=messages if 'messages' in locals() else [],
                llm_response=None,
                usage=None,
                error=error_msg
            )
            
            return f"D√©sol√©e, j'ai rencontr√© une erreur : {str(e)}"
    
    def _process_memory_action(self, response_text):
        """
        Extrait et ex√©cute une action m√©moire depuis la r√©ponse du LLM
        
        Returns:
            str: Message de r√©sultat de l'action, ou None
        """
        try:
            # Chercher un bloc JSON dans la r√©ponse
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if not json_match:
                return None
            
            # Parser le JSON
            intent = json.loads(json_match.group(1))
            action = intent.get('memory_action')
            
            if not action:
                return None
            
            # Ex√©cuter l'action correspondante
            if action == 'save_note':
                content = intent.get('content', '')
                tags = intent.get('tags')
                item_id = save_note(content=content, tags=tags)
                return f"‚úì Note sauvegard√©e (ID: {item_id})"
            
            elif action == 'list_notes':
                items = get_items(type='note', limit=50)
                if not items:
                    return "Aucune note en m√©moire."
                result = f"üìù {len(items)} note(s) trouv√©e(s) :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:50]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'search_notes':
                query = intent.get('query', '')
                items = search_items(query=query, type='note', limit=50)
                if not items:
                    return f"Aucune note trouv√©e pour '{query}'."
                result = f"üîç {len(items)} note(s) trouv√©e(s) pour '{query}' :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:50]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'save_todo':
                content = intent.get('content', '')
                tags = intent.get('tags')
                item_id = save_todo(content=content, tags=tags)
                return f"‚úì Todo sauvegard√© (ID: {item_id})"
            
            elif action == 'list_todos':
                items = get_items(type='todo', limit=50)
                if not items:
                    return "Aucun todo en m√©moire."
                result = f"‚úÖ {len(items)} todo(s) trouv√©(s) :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:50]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'search_todos':
                query = intent.get('query', '')
                items = search_items(query=query, type='todo', limit=50)
                if not items:
                    return f"Aucun todo trouv√© pour '{query}'."
                result = f"üîç {len(items)} todo(s) trouv√©(s) pour '{query}' :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:50]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'save_process':
                content = intent.get('content', '')
                tags = intent.get('tags')
                item_id = save_process(content=content, tags=tags)
                return f"‚úì Processus sauvegard√© (ID: {item_id})"
            
            elif action == 'list_processes':
                items = get_items(type='process', limit=50)
                if not items:
                    return "Aucun processus en m√©moire."
                result = f"‚öôÔ∏è {len(items)} processus trouv√©(s) :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:80]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'save_protocol':
                content = intent.get('content', '')
                tags = intent.get('tags')
                item_id = save_protocol(content=content, tags=tags)
                return f"‚úì Protocole sauvegard√© (ID: {item_id})"
            
            elif action == 'list_protocols':
                items = get_items(type='protocol', limit=50)
                if not items:
                    return "Aucun protocole en m√©moire."
                result = f"üìã {len(items)} protocole(s) trouv√©(s) :\n"
                for item in items[:10]:
                    result += f"  - ID {item['id']}: {item['content'][:80]}...\n"
                if len(items) > 10:
                    result += f"  ... et {len(items) - 10} autre(s)"
                return result
            
            elif action == 'set_preference':
                pref_dict = {
                    'scope': intent.get('scope', 'global'),
                    'agent': intent.get('agent'),
                    'domain': intent.get('domain', 'general'),
                    'key': intent.get('key'),
                    'value': intent.get('value'),
                    'source': intent.get('source', 'user'),
                    'confidence': intent.get('confidence', 1.0)
                }
                if pref_dict['key'] and pref_dict['value']:
                    success = save_preference(pref_dict)
                    if success:
                        # Sauvegarder aussi dans memory avec tags
                        from memory.helpers import save_note
                        tags = ["preference", pref_dict.get('domain', 'general'), pref_dict.get('agent') or 'global']
                        save_note(f"Pr√©f√©rence: {pref_dict['key']} = {pref_dict['value']}", tags=tags)
                        return f"‚úì Pr√©f√©rence enregistr√©e : {pref_dict['key']} = {pref_dict['value']}"
                    else:
                        return "‚ö† Erreur lors de l'enregistrement de la pr√©f√©rence"
                return "‚ö† Cl√© ou valeur manquante pour la pr√©f√©rence"
            
            elif action == 'delete_item':
                item_id = intent.get('item_id')
                if item_id:
                    delete_item(item_id=item_id)
                    return f"‚úì √âl√©ment {item_id} supprim√©"
                return "‚ö† ID manquant pour la suppression"
            
            return None
            
        except (json.JSONDecodeError, Exception) as e:
            # En cas d'erreur de parsing ou d'ex√©cution, ne pas planter
            return None
    
    def _check_memory_read_intent(self, user_message):
        """
        Pr√©-v√©rifie si le message demande une lecture m√©moire
        Si oui, interroge la DB AVANT l'appel LLM pour √©viter hallucinations
        
        D√©tecte aussi les intentions de pr√©f√©rences
        
        Returns:
            str: Contexte m√©moire format√©, ou None
        """
        msg_lower = user_message.lower()
        
        # D√©tection des pr√©f√©rences
        preference_keywords = [
            'je pr√©f√®re', 'je pr√©f√©rerais', 'pr√©f√®re', 'pr√©f√©rerais',
            'd√©sormais', '√† partir de maintenant', 'dor√©navant',
            'toujours', 'jamais', 'ne jamais',
            'souhaite que', 'veux que'
        ]
        is_preference_intent = any(kw in msg_lower for kw in preference_keywords)
        
        if is_preference_intent:
            # Retourner un contexte pour aider le LLM √† g√©n√©rer l'intention JSON
            return "L'utilisateur exprime une pr√©f√©rence. G√©n√®re une intention JSON avec memory_action='set_preference'."
        
        # D√©tection basique d'intentions de lecture
        keywords_list = ['montre', 'liste', 'affiche', 'voir', 'consulte', 'lis']
        keywords_search = ['cherche', 'trouve', 'recherche']
        
        is_list_intent = any(kw in msg_lower for kw in keywords_list)
        is_search_intent = any(kw in msg_lower for kw in keywords_search)
        
        if not (is_list_intent or is_search_intent):
            return None
        
        # D√©tecter le type demand√©
        result_parts = []
        
        if 'note' in msg_lower:
            if is_search_intent:
                # Extraire le mot-cl√© de recherche (simpliste)
                words = msg_lower.split()
                query = ' '.join(words[-3:])  # Derniers mots comme approximation
                items = search_items(query=query, type='note', limit=20)
                result_parts.append(f"NOTES (recherche '{query}'): {len(items)} trouv√©e(s)")
            else:
                items = get_items(type='note', limit=20)
                result_parts.append(f"NOTES: {len(items)} en m√©moire")
            
            for item in items[:5]:
                result_parts.append(f"  - ID {item['id']}: {item['content'][:60]}")
        
        if 'todo' in msg_lower:
            items = get_items(type='todo', limit=20)
            result_parts.append(f"TODOS: {len(items)} en m√©moire")
            for item in items[:5]:
                result_parts.append(f"  - ID {item['id']}: {item['content'][:60]}")
        
        if 'process' in msg_lower or 'processus' in msg_lower or 'proc√©dure' in msg_lower:
            items = get_items(type='process', limit=20)
            result_parts.append(f"PROCESSUS: {len(items)} en m√©moire")
            for item in items[:5]:
                result_parts.append(f"  - ID {item['id']}: {item['content'][:60]}")
        
        if 'protocol' in msg_lower or 'protocole' in msg_lower:
            items = get_items(type='protocol', limit=20)
            result_parts.append(f"PROTOCOLES: {len(items)} en m√©moire")
            for item in items[:5]:
                result_parts.append(f"  - ID {item['id']}: {item['content'][:60]}")
        
        if result_parts:
            return '\n'.join(result_parts)
        
        return None
    
    def _clean_response(self, response_text):
        """Nettoie la r√©ponse en enlevant le bloc JSON"""
        return re.sub(r'```json\s*\{.*?\}\s*```', '', response_text, flags=re.DOTALL).strip()
    
    def _build_prompt(self):
        """Construit le prompt complet avec system + historique"""
        messages = [
            {'role': 'system', 'content': self.system_prompt}
        ]
        
        # Ajouter l'historique
        messages.extend(self.conversation_history)
        
        return messages
